{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/miniconda3/envs/torch-mlir/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_mlir\n",
    "\n",
    "from transformers import BertForMaskedLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "# Wrap the bert model to avoid multiple returns problem\n",
    "\n",
    "\n",
    "class BertTinyWrapper(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.bert = BertForMaskedLM.from_pretrained(\n",
    "            \"prajjwal1/bert-tiny\", return_dict=False)\n",
    "\n",
    "    # def forward(self, data):\n",
    "    #     with profiler.record_function('fwd'):\n",
    "    #         o= self.bert(data)[0]\n",
    "    #     return o\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self.bert(data)[0]\n",
    "\n",
    "\n",
    "model = BertTinyWrapper()\n",
    "model.eval()\n",
    "data = torch.randint(30522, (2, 128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                aten::addmm        66.87%       8.500ms        78.57%       9.988ms     713.429us            14  \n",
      "                aten::copy_        13.31%       1.692ms        13.31%       1.692ms      62.667us            27  \n",
      "                  aten::bmm         3.34%     425.000us         3.34%     425.000us     106.250us             4  \n",
      "                 aten::gelu         3.30%     419.000us         3.30%     419.000us     139.667us             3  \n",
      "    aten::native_layer_norm         3.12%     396.000us         3.28%     417.000us      69.500us             6  \n",
      "                  aten::add         1.53%     195.000us         1.53%     195.000us      27.857us             7  \n",
      "               aten::linear         0.93%     118.000us        80.86%      10.279ms     734.214us            14  \n",
      "                  aten::div         0.87%     111.000us         0.98%     125.000us      62.500us             2  \n",
      "                 aten::view         0.69%      88.000us         0.69%      88.000us       1.600us            55  \n",
      "             aten::_softmax         0.67%      85.000us         0.67%      85.000us      42.500us             2  \n",
      "                    aten::t         0.55%      70.000us         0.85%     108.000us       7.714us            14  \n",
      "         aten::index_select         0.50%      64.000us         0.60%      76.000us      25.333us             3  \n",
      "           aten::layer_norm         0.39%      50.000us         3.41%     434.000us      72.333us             6  \n",
      "                aten::empty         0.39%      49.000us         0.39%      49.000us       1.581us            31  \n",
      "               aten::expand         0.35%      45.000us         0.38%      48.000us       2.087us            23  \n",
      "            aten::embedding         0.30%      38.000us         1.05%     134.000us      44.667us             3  \n",
      "            aten::transpose         0.30%      38.000us         0.35%      45.000us       2.812us            16  \n",
      "               aten::matmul         0.29%      37.000us         5.59%     711.000us     177.750us             4  \n",
      "                aten::clone         0.27%      34.000us         2.23%     283.000us      31.444us             9  \n",
      "                aten::slice         0.24%      30.000us         0.27%      34.000us       5.667us             6  \n",
      "              aten::reshape         0.21%      27.000us         1.90%     241.000us      21.909us            11  \n",
      "              aten::permute         0.21%      27.000us         0.23%      29.000us       3.625us             8  \n",
      "                   aten::to         0.20%      25.000us         0.29%      37.000us       7.400us             5  \n",
      "             aten::_to_copy         0.16%      20.000us         0.23%      29.000us       7.250us             4  \n",
      "         aten::_unsafe_view         0.13%      17.000us         0.13%      17.000us       1.545us            11  \n",
      "                 aten::ones         0.13%      16.000us         0.22%      28.000us      28.000us             1  \n",
      "           aten::as_strided         0.13%      16.000us         0.13%      16.000us       0.262us            61  \n",
      "                  aten::mul         0.11%      14.000us         0.16%      20.000us      20.000us             1  \n",
      "                 aten::add_         0.10%      13.000us         0.10%      13.000us      13.000us             1  \n",
      "           aten::empty_like         0.09%      12.000us         0.27%      34.000us       3.778us             9  \n",
      "                 aten::rsub         0.09%      11.000us         0.34%      43.000us      43.000us             1  \n",
      "               aten::select         0.09%      11.000us         0.09%      11.000us       1.833us             6  \n",
      "                aten::fill_         0.05%       6.000us         0.05%       6.000us       6.000us             1  \n",
      "            aten::unsqueeze         0.05%       6.000us         0.05%       6.000us       3.000us             2  \n",
      "              aten::softmax         0.05%       6.000us         0.72%      91.000us      45.500us             2  \n",
      "        aten::empty_strided         0.02%       3.000us         0.02%       3.000us       0.750us             4  \n",
      "           aten::contiguous         0.01%       1.000us         0.68%      86.000us      43.000us             2  \n",
      "              aten::dropout         0.00%       0.000us         0.00%       0.000us       0.000us             7  \n",
      "         aten::resolve_conj         0.00%       0.000us         0.00%       0.000us       0.000us            36  \n",
      "                  aten::sub        -0.02%      -3.000us         0.25%      32.000us      32.000us             1  \n",
      "---------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 12.712ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/miniconda3/envs/torch-mlir/lib/python3.11/site-packages/torch/autograd/profiler.py:204: UserWarning: CUDA is not available, disabling CUDA profiling\n",
      "  warn(\"CUDA is not available, disabling CUDA profiling\")\n",
      "STAGE:2023-04-15 02:24:40 6343:6343 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-04-15 02:24:40 6343:6343 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-04-15 02:24:40 6343:6343 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "with torch.profiler.profile(\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler('../output/log'),\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA,\n",
    "    ],\n",
    "    record_shapes=True,\n",
    "    with_stack=True,\n",
    ") as p:\n",
    "    model.forward(data)\n",
    "print(p.key_averages().table(\n",
    "    sort_by=\"self_cpu_time_total\", row_limit=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# Click this and select the right log directory\n",
    "# if you have already started tensorboard, it may lock your port\n",
    "# access it, open terminal and click in PORTS tab, than open the on vscode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with torch.profiler.profile(\n",
    "#     schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    "#     on_trace_ready=torch.profiler.tensorboard_trace_handler('./log'),\n",
    "#     record_shapes=True,\n",
    "#     profile_memory=True,\n",
    "#     with_stack=True,\n",
    "# ) as p:\n",
    "#     o = model.forward(data)\n",
    "\n",
    "# print(p.profiler().table())\n",
    "# print(o)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-mlir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
